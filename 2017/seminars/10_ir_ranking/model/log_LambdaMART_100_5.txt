
[+] General Parameters:
Training data:	./data/train.txt
Test data:	./data/test.txt
Validation data:	./data/valid.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No
Model file: ./model/LambdaMART_100_5.txt

[+] LambdaMART's Parameters:
No. of trees: 100
No. of leaves: 5
No. of threshold candidates: 256
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [./data/train.txt]: 0... Reading feature file [./data/train.txt]... [Done.]            
(104 ranked lists, 1305 entries read)
Reading feature file [./data/valid.txt]: 0... Reading feature file [./data/valid.txt]... [Done.]            
(105 ranked lists, 975 entries read)
Reading feature file [./data/test.txt]: 0... Reading feature file [./data/test.txt]... [Done.]            
(76 ranked lists, 655 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@10-T | NDCG@10-V | 
---------------------------------
1       | 0.6722    | 0.5913    | 
2       | 0.6817    | 0.5921    | 
3       | 0.6807    | 0.5913    | 
4       | 0.6807    | 0.5913    | 
5       | 0.6807    | 0.5913    | 
6       | 0.6898    | 0.6074    | 
7       | 0.6898    | 0.6074    | 
8       | 0.6946    | 0.608     | 
9       | 0.7006    | 0.6036    | 
10      | 0.7005    | 0.6022    | 
11      | 0.7234    | 0.6168    | 
12      | 0.7258    | 0.6133    | 
13      | 0.731     | 0.6112    | 
14      | 0.7318    | 0.6113    | 
15      | 0.7318    | 0.6112    | 
16      | 0.732     | 0.6107    | 
17      | 0.743     | 0.6148    | 
18      | 0.7423    | 0.6162    | 
19      | 0.7429    | 0.616     | 
20      | 0.7422    | 0.6158    | 
21      | 0.7569    | 0.6218    | 
22      | 0.7553    | 0.6236    | 
23      | 0.7596    | 0.6262    | 
24      | 0.7589    | 0.6262    | 
25      | 0.762     | 0.6263    | 
26      | 0.7585    | 0.6274    | 
27      | 0.7587    | 0.6276    | 
28      | 0.7664    | 0.6278    | 
29      | 0.7656    | 0.6314    | 
30      | 0.7679    | 0.6306    | 
31      | 0.7719    | 0.6368    | 
32      | 0.7719    | 0.6356    | 
33      | 0.7783    | 0.6397    | 
34      | 0.7821    | 0.6418    | 
35      | 0.7836    | 0.6391    | 
36      | 0.7854    | 0.639     | 
37      | 0.7856    | 0.6399    | 
38      | 0.7863    | 0.6433    | 
39      | 0.7878    | 0.6419    | 
40      | 0.7869    | 0.6401    | 
41      | 0.7899    | 0.6385    | 
42      | 0.7911    | 0.6401    | 
43      | 0.7905    | 0.6421    | 
44      | 0.7924    | 0.6397    | 
45      | 0.7924    | 0.6402    | 
46      | 0.7916    | 0.6409    | 
47      | 0.792     | 0.6421    | 
48      | 0.7915    | 0.6413    | 
49      | 0.792     | 0.6378    | 
50      | 0.792     | 0.64      | 
51      | 0.7933    | 0.6384    | 
52      | 0.7937    | 0.6377    | 
53      | 0.7939    | 0.6352    | 
54      | 0.7987    | 0.6341    | 
55      | 0.8008    | 0.6367    | 
56      | 0.8025    | 0.6365    | 
57      | 0.8023    | 0.6336    | 
58      | 0.8028    | 0.6337    | 
59      | 0.8041    | 0.6329    | 
60      | 0.804     | 0.6334    | 
61      | 0.8049    | 0.6319    | 
62      | 0.8048    | 0.6315    | 
63      | 0.8072    | 0.6324    | 
64      | 0.8086    | 0.6335    | 
65      | 0.8096    | 0.6322    | 
66      | 0.8099    | 0.6313    | 
67      | 0.8131    | 0.6311    | 
68      | 0.8128    | 0.631     | 
69      | 0.8132    | 0.6314    | 
70      | 0.8131    | 0.6322    | 
71      | 0.813     | 0.6326    | 
72      | 0.813     | 0.6341    | 
73      | 0.8127    | 0.6349    | 
74      | 0.813     | 0.6353    | 
75      | 0.8135    | 0.6339    | 
76      | 0.8136    | 0.6346    | 
77      | 0.8128    | 0.6337    | 
78      | 0.8133    | 0.6317    | 
79      | 0.8162    | 0.6314    | 
80      | 0.818     | 0.6331    | 
81      | 0.8182    | 0.6355    | 
82      | 0.8183    | 0.6324    | 
83      | 0.82      | 0.6336    | 
84      | 0.82      | 0.6348    | 
85      | 0.8202    | 0.634     | 
86      | 0.8197    | 0.6334    | 
87      | 0.8199    | 0.6357    | 
88      | 0.8197    | 0.6366    | 
89      | 0.8205    | 0.6344    | 
90      | 0.821     | 0.6352    | 
91      | 0.8212    | 0.6347    | 
92      | 0.8219    | 0.6351    | 
93      | 0.8221    | 0.6376    | 
94      | 0.8226    | 0.6369    | 
95      | 0.8233    | 0.6374    | 
96      | 0.825     | 0.6368    | 
97      | 0.8247    | 0.638     | 
98      | 0.8236    | 0.6386    | 
99      | 0.8239    | 0.639     | 
100     | 0.8241    | 0.6396    | 
---------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.7863
NDCG@10 on validation data: 0.6433
---------------------------------
NDCG@10 on test data: 0.6976

Model saved to: ./model/LambdaMART_100_5.txt
