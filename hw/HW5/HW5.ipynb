{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Simple q-learning agent with experience replay\n",
    "\n",
    "We re-write q-learning algorithm using _agentnet_ - a helper for lasagne that implements some RL techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/yandexdataschool/AgentNet/archive/master.zip\n",
      "  Downloading https://github.com/yandexdataschool/AgentNet/archive/master.zip (11.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 11.7MB 85kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: six in /usr/local/lib/python2.7/site-packages (from agentnet==0.10.6)\n",
      "Requirement already up-to-date: lasagne in /usr/local/lib/python2.7/site-packages (from agentnet==0.10.6)\n",
      "Requirement already up-to-date: theano>=0.8.2 in /usr/local/lib/python2.7/site-packages (from agentnet==0.10.6)\n",
      "Requirement already up-to-date: numpy>=1.9 in /usr/local/lib/python2.7/site-packages (from agentnet==0.10.6)\n",
      "Requirement already up-to-date: scipy>=0.14 in /usr/local/lib/python2.7/site-packages (from theano>=0.8.2->agentnet==0.10.6)\n",
      "Installing collected packages: agentnet\n",
      "  Found existing installation: agentnet 0.10.6\n",
      "    Uninstalling agentnet-0.10.6:\n",
      "      Successfully uninstalled agentnet-0.10.6\n",
      "  Running setup.py install for agentnet ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25hSuccessfully installed agentnet-0.10.6\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade https://github.com/yandexdataschool/AgentNet/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS='floatX=float32'\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Experiment setup\n",
    "* Here we simply load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:29:21,208] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"LunarLander-v2\")\n",
    "\n",
    "env=make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npE4Z8JLUKQNekjr1/wHF3gTeA8rWwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1085b78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Network body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import elu\n",
    "\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,)+state_shape)\n",
    "\n",
    "layer = DenseLayer(observation_layer, 100, nonlinearity=elu)\n",
    "layer = DenseLayer(layer, 200, nonlinearity=elu)\n",
    "\n",
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(layer,num_units=n_actions,\n",
    "                           nonlinearity=None,name=\"q-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Picking actions is done by yet another layer, that implements $ \\epsilon$ -greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "#set starting epsilon\n",
    "action_layer.epsilon.set_value(np.float32(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Agent\n",
    "\n",
    "We define an agent entirely composed of a lasagne network:\n",
    "* Observations as InputLayer(s)\n",
    "* Actions as intermediate Layer(s)\n",
    "* `policy_estimators` is \"whatever else you want to keep track of\"\n",
    "\n",
    "Each parameter can be either one layer or a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              action_layers=action_layer,\n",
    "              policy_estimators=qvalues_layer,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, q-values.W, q-values.b]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:30:31,702] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "pool = EnvPool(agent,make_env,n_games=1,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('actions:', array([[0, 0, 3, 0, 0]]))\n",
      "('rewards:', array([[1.76360684, 1.88618985, 1.56593652, 1.7995859 , 0.        ]]))\n",
      "CPU times: user 5.9 ms, sys: 3.68 ms, total: 9.58 ms\n",
      "Wall time: 17.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "obs_log,action_log,reward_log,_,_,_  = pool.interact(5)\n",
    "\n",
    "\n",
    "print('actions:',action_log)\n",
    "print('rewards:',reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we'll train on rollouts of 10 steps (required by n-step algorithms and rnns later)\n",
    "SEQ_LENGTH=10\n",
    "\n",
    "#load first sessions (this function calls interact and stores sessions in the pool)\n",
    "\n",
    "for _ in range(100):\n",
    "    pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# q-learning\n",
    "\n",
    "We shall now define a function that replays recent game sessions and updates network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100)\n",
    "qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2, like you implemented before in lasagne.\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,\n",
    "                                                      n_steps=1,)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get weight updates\n",
    "updates = lasagne.updates.adam(loss,weights,learning_rate=1e-4)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Demo run\n",
    "\n",
    "Play full session with an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:31:56,944] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:31:56,955] Creating monitor directory ./records\n",
      "[2018-02-02 23:31:56,959] Starting new video recorder writing to /Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records/openaigym.video.0.2487.video000000.mp4\n",
      "[2018-02-02 23:31:58,797] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 85 timesteps with reward=-487.614407234\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.2487.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1 #starting epoch\n",
    "rewards = {} #full game rewards\n",
    "target_score = -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 98/10000 [00:03<06:44, 24.50it/s][2018-02-02 23:33:44,841] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:33:44,848] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:33:44,976] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  1%|          | 100/10000 [00:04<06:57, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 104 timesteps with reward=-296.954534809\n",
      "Episode finished after 65 timesteps with reward=-121.228915335\n",
      "Episode finished after 88 timesteps with reward=-87.1448991751\n",
      "iter=100\tepsilon=0.910\n",
      "Current score(mean over 3) = -168.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/10000 [00:08<06:46, 24.10it/s][2018-02-02 23:33:49,068] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:33:49,079] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:33:49,249] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 77 timesteps with reward=-103.249217352\n",
      "Episode finished after 121 timesteps with reward=-390.633116471\n",
      "Episode finished after 118 timesteps with reward=-506.985277236\n",
      "iter=200\tepsilon=0.828\n",
      "Current score(mean over 3) = -333.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 298/10000 [00:12<07:02, 22.96it/s][2018-02-02 23:33:53,830] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:33:53,840] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 188 timesteps with reward=-326.925074313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:33:55,436] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  3%|▎         | 301/10000 [00:14<07:54, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=15.5409240645\n",
      "Episode finished after 89 timesteps with reward=-304.960264375\n",
      "iter=300\tepsilon=0.754\n",
      "Current score(mean over 3) = -205.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 397/10000 [00:19<07:40, 20.84it/s][2018-02-02 23:33:59,978] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:33:59,987] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:00,274] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 131 timesteps with reward=-421.826865106\n",
      "Episode finished after 88 timesteps with reward=-250.829689356\n",
      "Episode finished after 242 timesteps with reward=-232.663551697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 403/10000 [00:19<07:48, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.687\n",
      "Current score(mean over 3) = -301.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 498/10000 [00:24<07:45, 20.43it/s][2018-02-02 23:34:05,253] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:05,261] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:05,450] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  5%|▌         | 501/10000 [00:24<07:49, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 121 timesteps with reward=-204.572037941\n",
      "Episode finished after 140 timesteps with reward=-395.065651293\n",
      "Episode finished after 75 timesteps with reward=-416.815749015\n",
      "iter=500\tepsilon=0.626\n",
      "Current score(mean over 3) = -338.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 598/10000 [00:29<07:46, 20.14it/s][2018-02-02 23:34:10,573] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:10,583] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:10,814] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 107 timesteps with reward=-380.209481372\n",
      "Episode finished after 160 timesteps with reward=-541.872990116\n",
      "Episode finished after 148 timesteps with reward=-290.126998534\n",
      "iter=600\tepsilon=0.571\n",
      "Current score(mean over 3) = -404.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 699/10000 [00:35<07:47, 19.88it/s][2018-02-02 23:34:15,965] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:15,972] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:16,136] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  7%|▋         | 701/10000 [00:35<07:50, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 83 timesteps with reward=-368.671879627\n",
      "Episode finished after 144 timesteps with reward=-410.943652793\n",
      "Episode finished after 82 timesteps with reward=-333.940591041\n",
      "iter=700\tepsilon=0.522\n",
      "Current score(mean over 3) = -371.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 799/10000 [00:41<08:02, 19.06it/s][2018-02-02 23:34:22,728] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:22,736] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:22,919] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  8%|▊         | 801/10000 [00:42<08:04, 18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 130 timesteps with reward=-573.74642093\n",
      "Episode finished after 116 timesteps with reward=-419.612215351\n",
      "Episode finished after 131 timesteps with reward=-265.03225093\n",
      "iter=800\tepsilon=0.477\n",
      "Current score(mean over 3) = -419.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 899/10000 [00:47<08:02, 18.86it/s][2018-02-02 23:34:28,483] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:28,492] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:28,634] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      "  9%|▉         | 901/10000 [00:47<08:04, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 98 timesteps with reward=-489.2086515\n",
      "Episode finished after 110 timesteps with reward=-488.48554717\n",
      "Episode finished after 90 timesteps with reward=-158.190433033\n",
      "iter=900\tepsilon=0.436\n",
      "Current score(mean over 3) = -378.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [00:54<08:11, 18.32it/s][2018-02-02 23:34:35,440] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:35,448] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:35,790] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 10%|█         | 1000/10000 [00:55<08:15, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 288 timesteps with reward=-815.596200816\n",
      "Episode finished after 138 timesteps with reward=-652.353391355\n",
      "Episode finished after 101 timesteps with reward=-246.900702215\n",
      "iter=1000\tepsilon=0.399\n",
      "Current score(mean over 3) = -571.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1099/10000 [01:01<08:20, 17.78it/s][2018-02-02 23:34:42,618] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:42,625] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:42,790] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 11%|█         | 1101/10000 [01:02<08:21, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 89 timesteps with reward=-292.663124075\n",
      "Episode finished after 94 timesteps with reward=-395.590120238\n",
      "Episode finished after 128 timesteps with reward=-570.103040297\n",
      "iter=1100\tepsilon=0.366\n",
      "Current score(mean over 3) = -419.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1199/10000 [01:07<08:18, 17.64it/s][2018-02-02 23:34:48,782] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:48,790] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:34:49,133] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 218 timesteps with reward=-620.317006863\n",
      "Episode finished after 155 timesteps with reward=-703.212498827\n",
      "Episode finished after 92 timesteps with reward=-312.375760642\n",
      "iter=1200\tepsilon=0.336\n",
      "Current score(mean over 3) = -545.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1299/10000 [01:14<08:18, 17.44it/s][2018-02-02 23:34:55,313] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:34:55,321] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 363 timesteps with reward=-899.085426349\n",
      "Episode finished after 173 timesteps with reward=-601.110787917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:34:55,843] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 13%|█▎        | 1303/10000 [01:15<08:22, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 195 timesteps with reward=-393.858745726\n",
      "iter=1300\tepsilon=0.309\n",
      "Current score(mean over 3) = -631.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1399/10000 [01:21<08:23, 17.08it/s][2018-02-02 23:35:02,728] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:02,736] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 182 timesteps with reward=-294.653449894\n",
      "Episode finished after 224 timesteps with reward=-450.72139049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:35:03,186] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 14%|█▍        | 1401/10000 [01:22<08:26, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 246 timesteps with reward=-844.780504017\n",
      "iter=1400\tepsilon=0.284\n",
      "Current score(mean over 3) = -530.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1498/10000 [01:30<08:34, 16.53it/s][2018-02-02 23:35:11,493] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:11,501] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 267 timesteps with reward=-504.182885251\n",
      "Episode finished after 225 timesteps with reward=-404.088339539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:35:11,957] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 15%|█▌        | 1502/10000 [01:31<08:36, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 194 timesteps with reward=-413.243130891\n",
      "iter=1500\tepsilon=0.262\n",
      "Current score(mean over 3) = -440.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1598/10000 [01:39<08:45, 15.99it/s][2018-02-02 23:35:20,834] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:20,842] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 273 timesteps with reward=-654.11767959\n",
      "Episode finished after 191 timesteps with reward=-710.839784632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:35:21,259] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 16%|█▌        | 1602/10000 [01:40<08:47, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 210 timesteps with reward=-322.907646717\n",
      "iter=1600\tepsilon=0.242\n",
      "Current score(mean over 3) = -562.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1699/10000 [01:48<08:51, 15.62it/s][2018-02-02 23:35:29,634] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:29,642] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:35:29,788] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 17%|█▋        | 1701/10000 [01:49<08:52, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-285.143418162\n",
      "Episode finished after 84 timesteps with reward=-389.436132983\n",
      "Episode finished after 97 timesteps with reward=-166.538499894\n",
      "iter=1700\tepsilon=0.224\n",
      "Current score(mean over 3) = -280.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1799/10000 [01:56<08:53, 15.38it/s][2018-02-02 23:35:37,814] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:37,823] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 108 timesteps with reward=-200.459412965\n",
      "Episode finished after 190 timesteps with reward=-245.504469089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:35:38,677] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 18%|█▊        | 1801/10000 [01:58<08:57, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 600 timesteps with reward=-433.012754558\n",
      "iter=1800\tepsilon=0.207\n",
      "Current score(mean over 3) = -292.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1898/10000 [02:06<09:01, 14.95it/s][2018-02-02 23:35:47,919] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:47,928] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:35:48,136] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 19%|█▉        | 1900/10000 [02:07<09:03, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 195 timesteps with reward=-171.1125644\n",
      "Episode finished after 88 timesteps with reward=-103.526850895\n",
      "Episode finished after 87 timesteps with reward=-123.329594364\n",
      "iter=1900\tepsilon=0.192\n",
      "Current score(mean over 3) = -132.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [02:16<09:05, 14.66it/s][2018-02-02 23:35:57,244] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:35:57,252] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 131 timesteps with reward=-116.372554217\n",
      "Episode finished after 234 timesteps with reward=-325.674257251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:35:57,666] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 20%|██        | 2001/10000 [02:17<09:07, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 244 timesteps with reward=-327.594565664\n",
      "iter=2000\tepsilon=0.179\n",
      "Current score(mean over 3) = -256.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2099/10000 [02:25<09:08, 14.40it/s][2018-02-02 23:36:06,633] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:06,641] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 286 timesteps with reward=-261.999056175\n",
      "Episode finished after 436 timesteps with reward=-270.97476425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:36:07,787] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 21%|██        | 2101/10000 [02:27<09:13, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 357 timesteps with reward=-287.442293338\n",
      "iter=2100\tepsilon=0.166\n",
      "Current score(mean over 3) = -273.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2198/10000 [02:37<09:20, 13.93it/s][2018-02-02 23:36:18,753] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:18,761] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 413 timesteps with reward=-422.570678065\n",
      "Episode finished after 216 timesteps with reward=-212.312706279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:36:19,376] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 22%|██▏       | 2200/10000 [02:38<09:22, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 236 timesteps with reward=-255.349857964\n",
      "iter=2200\tepsilon=0.155\n",
      "Current score(mean over 3) = -296.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2299/10000 [02:47<09:20, 13.75it/s][2018-02-02 23:36:28,047] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:28,055] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:36:28,212] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 23%|██▎       | 2301/10000 [02:47<09:20, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 98 timesteps with reward=-224.321503825\n",
      "Episode finished after 99 timesteps with reward=-194.857557267\n",
      "Episode finished after 90 timesteps with reward=-444.546613334\n",
      "iter=2300\tepsilon=0.145\n",
      "Current score(mean over 3) = -287.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2399/10000 [02:55<09:15, 13.68it/s][2018-02-02 23:36:36,165] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:36,173] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 147 timesteps with reward=-294.274681352\n",
      "Episode finished after 198 timesteps with reward=-178.371209142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:36:36,703] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 24%|██▍       | 2401/10000 [02:56<09:17, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 356 timesteps with reward=-342.24390786\n",
      "iter=2400\tepsilon=0.136\n",
      "Current score(mean over 3) = -271.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [03:04<09:13, 13.56it/s][2018-02-02 23:36:45,104] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:45,112] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:36:45,264] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 25%|██▌       | 2501/10000 [03:04<09:13, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 95 timesteps with reward=-301.225929812\n",
      "Episode finished after 106 timesteps with reward=-213.483925081\n",
      "Episode finished after 93 timesteps with reward=-395.410927677\n",
      "iter=2500\tepsilon=0.128\n",
      "Current score(mean over 3) = -303.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2598/10000 [03:12<09:09, 13.48it/s][2018-02-02 23:36:53,665] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:36:53,672] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:36:53,914] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 26%|██▌       | 2600/10000 [03:13<09:09, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 85 timesteps with reward=-238.805244836\n",
      "Episode finished after 79 timesteps with reward=-488.117388331\n",
      "Episode finished after 237 timesteps with reward=-265.210691682\n",
      "iter=2600\tepsilon=0.121\n",
      "Current score(mean over 3) = -330.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2698/10000 [03:21<09:04, 13.41it/s][2018-02-02 23:37:02,099] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:02,106] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:37:02,300] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 27%|██▋       | 2700/10000 [03:21<09:04, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 142 timesteps with reward=-472.721042044\n",
      "Episode finished after 90 timesteps with reward=-572.39416577\n",
      "Episode finished after 102 timesteps with reward=-74.1486881188\n",
      "iter=2700\tepsilon=0.114\n",
      "Current score(mean over 3) = -373.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2798/10000 [03:29<08:58, 13.36it/s][2018-02-02 23:37:10,325] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:10,333] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 199 timesteps with reward=-409.595820422\n",
      "Episode finished after 201 timesteps with reward=-322.63308869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:37:10,679] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 28%|██▊       | 2802/10000 [03:30<08:59, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 149 timesteps with reward=-355.763015427\n",
      "iter=2800\tepsilon=0.108\n",
      "Current score(mean over 3) = -362.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2898/10000 [03:38<08:54, 13.29it/s][2018-02-02 23:37:19,014] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:19,023] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 292 timesteps with reward=-595.400554235\n",
      "Episode finished after 136 timesteps with reward=-61.246122753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:37:19,481] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 29%|██▉       | 2902/10000 [03:38<08:55, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 146 timesteps with reward=-335.528327487\n",
      "iter=2900\tepsilon=0.102\n",
      "Current score(mean over 3) = -330.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2998/10000 [03:47<08:51, 13.18it/s][2018-02-02 23:37:28,450] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:28,457] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 191 timesteps with reward=-389.976319169\n",
      "Episode finished after 167 timesteps with reward=-386.538233867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:37:28,863] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 30%|███       | 3002/10000 [03:48<08:52, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 194 timesteps with reward=-502.207735779\n",
      "iter=3000\tepsilon=0.097\n",
      "Current score(mean over 3) = -426.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3099/10000 [03:57<08:48, 13.07it/s][2018-02-02 23:37:38,017] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:38,026] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:37:38,644] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 433 timesteps with reward=-178.075120832\n",
      "Episode finished after 126 timesteps with reward=-35.1388364804\n",
      "Episode finished after 182 timesteps with reward=-212.888124684\n",
      "iter=3100\tepsilon=0.093\n",
      "Current score(mean over 3) = -142.034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3198/10000 [04:09<08:50, 12.83it/s][2018-02-02 23:37:50,246] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:37:50,259] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode finished after 312 timesteps with reward=-252.672233876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:37:51,089] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 32%|███▏      | 3200/10000 [04:10<08:51, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 285 timesteps with reward=-246.197518434\n",
      "Episode finished after 231 timesteps with reward=-369.434337547\n",
      "iter=3200\tepsilon=0.089\n",
      "Current score(mean over 3) = -289.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3299/10000 [04:20<08:49, 12.66it/s][2018-02-02 23:38:01,448] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:01,456] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 255 timesteps with reward=-106.784491238\n",
      "Episode finished after 112 timesteps with reward=-181.703249911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:01,881] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 33%|███▎      | 3301/10000 [04:21<08:50, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 191 timesteps with reward=-201.694291487\n",
      "iter=3300\tepsilon=0.085\n",
      "Current score(mean over 3) = -163.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3399/10000 [04:34<08:53, 12.38it/s][2018-02-02 23:38:15,418] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:15,427] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 318 timesteps with reward=-160.708972021\n",
      "Episode finished after 400 timesteps with reward=-350.666948382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:16,384] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 34%|███▍      | 3402/10000 [04:35<08:54, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 300 timesteps with reward=-152.438088919\n",
      "iter=3400\tepsilon=0.082\n",
      "Current score(mean over 3) = -221.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [04:45<08:50, 12.27it/s][2018-02-02 23:38:26,106] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:26,115] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 82 timesteps with reward=-260.914102106\n",
      "Episode finished after 256 timesteps with reward=-379.887246279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:26,468] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 35%|███▌      | 3501/10000 [04:45<08:50, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 194 timesteps with reward=-380.274633323\n",
      "iter=3500\tepsilon=0.079\n",
      "Current score(mean over 3) = -340.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3598/10000 [04:55<08:46, 12.16it/s][2018-02-02 23:38:36,787] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:36,797] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 267 timesteps with reward=-368.507173407\n",
      "Episode finished after 250 timesteps with reward=-356.232059223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:38,285] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 36%|███▌      | 3601/10000 [04:57<08:48, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 617 timesteps with reward=-396.794148267\n",
      "iter=3600\tepsilon=0.076\n",
      "Current score(mean over 3) = -373.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3699/10000 [05:06<08:42, 12.06it/s][2018-02-02 23:38:47,665] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:47,673] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 278 timesteps with reward=-452.00340381\n",
      "Episode finished after 289 timesteps with reward=-333.222452133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:48,396] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 37%|███▋      | 3702/10000 [05:07<08:43, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 271 timesteps with reward=-389.390741332\n",
      "iter=3700\tepsilon=0.073\n",
      "Current score(mean over 3) = -391.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3799/10000 [05:17<08:37, 11.98it/s][2018-02-02 23:38:57,877] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:38:57,885] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 247 timesteps with reward=-229.708186429\n",
      "Episode finished after 206 timesteps with reward=-62.442274723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:38:58,302] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 38%|███▊      | 3801/10000 [05:17<08:38, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 125 timesteps with reward=-397.465580018\n",
      "iter=3800\tepsilon=0.071\n",
      "Current score(mean over 3) = -229.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3898/10000 [05:26<08:31, 11.92it/s][2018-02-02 23:39:07,834] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:07,842] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 164 timesteps with reward=-256.96949133\n",
      "Episode finished after 315 timesteps with reward=-395.954009847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:08,668] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 39%|███▉      | 3901/10000 [05:28<08:32, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 378 timesteps with reward=-344.416611004\n",
      "iter=3900\tepsilon=0.069\n",
      "Current score(mean over 3) = -332.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3998/10000 [05:38<08:27, 11.83it/s][2018-02-02 23:39:19,036] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:19,044] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 196 timesteps with reward=-36.6738408823\n",
      "Episode finished after 197 timesteps with reward=-238.412346762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:19,459] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 40%|████      | 4001/10000 [05:38<08:27, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 196 timesteps with reward=-290.042565029\n",
      "iter=4000\tepsilon=0.067\n",
      "Current score(mean over 3) = -188.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4099/10000 [05:47<08:20, 11.78it/s][2018-02-02 23:39:28,723] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:28,731] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 148 timesteps with reward=-535.393065578\n",
      "Episode finished after 119 timesteps with reward=-483.325736172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:29,089] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 41%|████      | 4101/10000 [05:48<08:21, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 261 timesteps with reward=-400.967557411\n",
      "iter=4100\tepsilon=0.066\n",
      "Current score(mean over 3) = -473.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4199/10000 [05:56<08:13, 11.76it/s][2018-02-02 23:39:37,796] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:37,804] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 246 timesteps with reward=-301.743806413\n",
      "Episode finished after 194 timesteps with reward=-47.0714958834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:38,261] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 42%|████▏     | 4201/10000 [05:57<08:13, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 207 timesteps with reward=-270.77348585\n",
      "iter=4200\tepsilon=0.064\n",
      "Current score(mean over 3) = -206.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4299/10000 [06:06<08:06, 11.72it/s][2018-02-02 23:39:47,699] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:47,707] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 241 timesteps with reward=-238.320905235\n",
      "Episode finished after 192 timesteps with reward=-206.32618071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:48,131] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 43%|████▎     | 4302/10000 [06:07<08:06, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 165 timesteps with reward=-183.608123963\n",
      "iter=4300\tepsilon=0.063\n",
      "Current score(mean over 3) = -209.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4399/10000 [06:17<08:01, 11.64it/s][2018-02-02 23:39:58,796] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:39:58,806] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 109 timesteps with reward=-120.325620058\n",
      "Episode finished after 222 timesteps with reward=-216.697055264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:39:59,164] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 44%|████▍     | 4401/10000 [06:18<08:01, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 152 timesteps with reward=-212.150742795\n",
      "iter=4400\tepsilon=0.062\n",
      "Current score(mean over 3) = -183.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [06:28<07:54, 11.59it/s][2018-02-02 23:40:09,145] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:09,155] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 150 timesteps with reward=-205.788729623\n",
      "Episode finished after 178 timesteps with reward=-23.803507788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:40:09,552] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 45%|████▌     | 4501/10000 [06:28<07:55, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 96 timesteps with reward=-177.833124466\n",
      "iter=4500\tepsilon=0.061\n",
      "Current score(mean over 3) = -135.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4599/10000 [06:38<07:48, 11.54it/s][2018-02-02 23:40:19,489] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:19,497] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 240 timesteps with reward=-61.4090859326\n",
      "Episode finished after 197 timesteps with reward=-160.916759659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:40:20,000] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 46%|████▌     | 4601/10000 [06:39<07:48, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 220 timesteps with reward=-230.119623404\n",
      "iter=4600\tepsilon=0.060\n",
      "Current score(mean over 3) = -150.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4699/10000 [06:49<07:41, 11.49it/s][2018-02-02 23:40:29,920] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:29,928] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:40:30,191] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 179 timesteps with reward=-220.577432665\n",
      "Episode finished after 97 timesteps with reward=-343.476989323\n",
      "Episode finished after 167 timesteps with reward=-135.922883282\n",
      "iter=4700\tepsilon=0.059\n",
      "Current score(mean over 3) = -233.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4798/10000 [06:57<07:33, 11.48it/s][2018-02-02 23:40:38,798] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:38,806] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:40:39,035] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 48%|████▊     | 4800/10000 [06:58<07:33, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 85 timesteps with reward=-712.755718712\n",
      "Episode finished after 177 timesteps with reward=-249.13621452\n",
      "Episode finished after 139 timesteps with reward=-297.825778718\n",
      "iter=4800\tepsilon=0.058\n",
      "Current score(mean over 3) = -419.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4898/10000 [07:06<07:24, 11.49it/s][2018-02-02 23:40:47,273] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:47,282] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 96 timesteps with reward=-336.603246816\n",
      "Episode finished after 208 timesteps with reward=-172.336220285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:40:47,661] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 49%|████▉     | 4902/10000 [07:07<07:24, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 269 timesteps with reward=-263.093812226\n",
      "iter=4900\tepsilon=0.057\n",
      "Current score(mean over 3) = -257.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [07:15<07:15, 11.49it/s][2018-02-02 23:40:55,945] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:40:55,953] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 164 timesteps with reward=-245.506770323\n",
      "Episode finished after 81 timesteps with reward=-573.45081769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:40:56,290] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 50%|█████     | 5001/10000 [07:15<07:15, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 274 timesteps with reward=-327.205267884\n",
      "iter=5000\tepsilon=0.056\n",
      "Current score(mean over 3) = -382.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5099/10000 [07:23<07:06, 11.49it/s][2018-02-02 23:41:04,639] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:41:04,647] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 168 timesteps with reward=-329.059675189\n",
      "Episode finished after 189 timesteps with reward=-341.299661637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:41:04,975] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 51%|█████     | 5101/10000 [07:24<07:06, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 179 timesteps with reward=-178.360262439\n",
      "iter=5100\tepsilon=0.056\n",
      "Current score(mean over 3) = -282.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5199/10000 [07:32<06:57, 11.49it/s][2018-02-02 23:41:13,156] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:41:13,164] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 155 timesteps with reward=-250.426740124\n",
      "Episode finished after 181 timesteps with reward=-343.043126066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:41:13,517] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 52%|█████▏    | 5201/10000 [07:32<06:57, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 216 timesteps with reward=-288.527877218\n",
      "iter=5200\tepsilon=0.055\n",
      "Current score(mean over 3) = -293.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5299/10000 [07:41<06:49, 11.48it/s][2018-02-02 23:41:22,298] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:41:22,307] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 178 timesteps with reward=-31.2369197521\n",
      "Episode finished after 158 timesteps with reward=-172.378254542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:41:22,674] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 53%|█████▎    | 5301/10000 [07:42<06:49, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 198 timesteps with reward=-296.908503924\n",
      "iter=5300\tepsilon=0.055\n",
      "Current score(mean over 3) = -166.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5398/10000 [07:50<06:41, 11.46it/s][2018-02-02 23:41:31,757] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:41:31,767] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:41:32,010] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n",
      " 54%|█████▍    | 5400/10000 [07:51<06:41, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 95 timesteps with reward=-171.516304009\n",
      "Episode finished after 100 timesteps with reward=-98.9613945041\n",
      "Episode finished after 176 timesteps with reward=-261.395382726\n",
      "iter=5400\tepsilon=0.054\n",
      "Current score(mean over 3) = -177.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5498/10000 [08:00<06:33, 11.45it/s][2018-02-02 23:41:40,980] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:41:40,989] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 209 timesteps with reward=-90.2268220994\n",
      "Episode finished after 181 timesteps with reward=-39.8283946982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:41:41,645] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 408 timesteps with reward=-60.4038619645\n",
      "iter=5500\tepsilon=0.054\n",
      "Current score(mean over 3) = -63.486\n",
      "You win!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 5498/10000 [08:10<06:41, 11.22it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(10000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1130ce750>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f4cf310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import ewma\n",
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda (k,v):k))\n",
    "plt.plot(iters,ewma(np.array(session_rewards),span=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:47:29,715] Making new env: LunarLander-v2\n",
      "[2018-02-02 23:47:29,725] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2018-02-02 23:47:29,728] Starting new video recorder writing to /Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records/openaigym.video.56.2487.video000000.mp4\n",
      "[2018-02-02 23:47:33,029] Starting new video recorder writing to /Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records/openaigym.video.56.2487.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 168 timesteps with reward=-66.9489493822\n",
      "Episode finished after 243 timesteps with reward=-132.725488259\n",
      "Episode finished after 212 timesteps with reward=-167.846737751\n",
      "Episode finished after 189 timesteps with reward=-56.784009607\n",
      "Episode finished after 238 timesteps with reward=-173.311767428\n",
      "Episode finished after 225 timesteps with reward=-152.199867131\n",
      "Episode finished after 233 timesteps with reward=-102.060288603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:47:38,568] Starting new video recorder writing to /Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records/openaigym.video.56.2487.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 204 timesteps with reward=-16.5843069481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-02-02 23:47:42,242] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/maximdankovtsev/Developer/ml-mipt-part2/hw/HW5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 199 timesteps with reward=-261.040989362\n",
      "Episode finished after 171 timesteps with reward=-173.758615319\n",
      "('average reward:', [-66.94894938223868, -132.7254882586081, -167.8467377509109, -56.78400960699836, -173.31176742760334, -152.1998671313281, -102.06028860307757, -16.58430694805722, -261.04098936198614, -173.75861531868625])\n"
     ]
    }
   ],
   "source": [
    "final_reward = pool.evaluate(n_games=10,save_path=\"./records\",record_video=True)\n",
    "\n",
    "print(\"average reward:\",final_reward)\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "for video_name in video_names:\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"{}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\".format(\"./records/\"+video_name)) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
